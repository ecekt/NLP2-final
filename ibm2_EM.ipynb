{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import dill\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231648\n"
     ]
    }
   ],
   "source": [
    "#read the training files and concatenate to create the training corpus\n",
    "\n",
    "##english\n",
    "train_e = 'training/hansards.36.2.e'\n",
    "test_e = 'testing/test/test.e'\n",
    "dev_e = 'validation/dev.e'\n",
    "# train_e = 'training/eng.e'\n",
    "\n",
    "##french\n",
    "train_f = 'training/hansards.36.2.f'\n",
    "test_f = 'testing/test/test.f'\n",
    "dev_f = 'validation/dev.f'\n",
    "# train_f = 'training/fra.f'\n",
    "\n",
    "null = ['0NULL']\n",
    "\n",
    "with open(train_e) as e:\n",
    "    sentences_e = [null + l.split() for l in e.readlines()]\n",
    "\n",
    "with open(test_e) as e:\n",
    "    for l in e.readlines():\n",
    "         sentences_e.append(null + l.split())\n",
    "\n",
    "with open(dev_e) as e:\n",
    "    for l in e.readlines():\n",
    "         sentences_e.append(null + l.split())\n",
    "\n",
    "    \n",
    "with open(train_f) as f:\n",
    "    sentences_f = [l.split() for l in f.readlines()]\n",
    "\n",
    "with open(test_f) as f:\n",
    "    for l in f.readlines():\n",
    "         sentences_f.append(l.split())\n",
    "\n",
    "with open(dev_f) as f:\n",
    "    for l in f.readlines():\n",
    "         sentences_f.append(l.split())\n",
    "\n",
    "no_sentences = len(sentences_e)\n",
    "print(no_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we preprocessed the corpus by replacing all the words that occur only once with <UNK>  \n",
    "#these corpora were not used in further experiments\n",
    "\n",
    "en_cnt = Counter()\n",
    "for sent in sentences_e:\n",
    "    for word in sent:\n",
    "        en_cnt[word.lower()] += 1\n",
    "\n",
    "new_sentences_e = []\n",
    "for sent in sentences_e:\n",
    "    sent = ['<UNK>' if en_cnt[word.lower()] == 1 else word for word in sent]\n",
    "    new_sentences_e.append(sent)\n",
    "\n",
    "fr_cnt = Counter()\n",
    "for sent in sentences_f:\n",
    "    for word in sent:\n",
    "        fr_cnt[word.lower()] += 1\n",
    "\n",
    "new_sentences_f = []\n",
    "for sent in sentences_f:\n",
    "    sent = ['<UNK>' if fr_cnt[word.lower()] == 1 else word for word in sent]\n",
    "    new_sentences_f.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#INIT TRANSLATION PROBABILITY\n",
    "# - randomly (3x)\n",
    "# - uniformly\n",
    "# - with the final results from IBM1\n",
    "\n",
    "t = defaultdict(lambda: defaultdict(int)) #create dictionary of transition probabilities\n",
    "\n",
    "for i in range (no_sentences):\n",
    "    sent_e = sentences_e[i] #new_sentences_e[i]\n",
    "    sent_f = sentences_f[i] #new_sentences_f[i]\n",
    "    \n",
    "    for word_e in sent_e:\n",
    "        for word_f in sent_f:\n",
    "            #initialize the translation probabilities t(f|e) randomly\n",
    "            t[word_f.lower()][word_e.lower()] = random.random()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_jump = 100\n",
    "jump_dist = 1. / (2 * max_jump) * np.ones([1, 2 * max_jump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jump_func(i, j, m, n):\n",
    "    \"\"\"\n",
    "    Alignment of french word j to english word i. \n",
    "    i = 0, to ,m  (we use m as in Wilker's lecture slides -- length of English sentence)\n",
    "    j = 1, to ,n  (we use n as in Wilker's lecture slides -- length of French sentence)\n",
    "    That is: a_j = i\n",
    "    with e.g. max_jump = 100\n",
    "    from[-max_jump, max_jump] to [0, 2*max_jump + 1] \n",
    "    \"\"\"\n",
    "    # We normalise j by the length of the French sentence and scale the result to the length of the English sentence\n",
    "    # this gives us a continuous value that is an interpolation of where we j would be in the English sentence\n",
    "    # if alignments were a linear function of the length ratio\n",
    "    jump = np.floor(i - (j * m / n)) \n",
    "    # then we collapse all jumps that are too far to the right to the maximum jump value allowed\n",
    "    if jump >= max_jump:  # or we collapse all jumps that are too far to the left to the maximum (negative) jump allowed\n",
    "        jump = max_jump - 1  \n",
    "    elif jump < -max_jump: #this does not need equality\n",
    "        jump = -max_jump\n",
    "    # Now we shift the jump values so they start from 0\n",
    "    #  this is only necessary if you use python lists or numpy vectors to store jump probabilities\n",
    "    #  otherwise, you can use a python dict and this shifting is not required since dicts can have negative keys\n",
    "    return jump + max_jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0050000000000000001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_jump = 100\n",
    "jump_dist[0, int(jump_func(2, 1, 12, 12))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Init with results from IBM1\n",
    "with open('transprobs_9.pickle', 'rb') as f:\n",
    "    t = dill.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#INIT ALIGNMENT PROBABILITIES\n",
    "q = defaultdict(lambda: defaultdict(int))\n",
    "vocab_size = 43196\n",
    "\n",
    "#Initialization of the q probabilities\n",
    "for sent in range(no_sentences):\n",
    "    sent_e = sentences_e[sent] #new_sentences_e[sent]\n",
    "    sent_f = sentences_f[sent] #new_sentences_f[sent]\n",
    "    \n",
    "    m = len(sent_f) \n",
    "    l = len(sent_e)\n",
    "    \n",
    "    for i in range(m): #english\n",
    "        for j in range(l): #french\n",
    "            q[j][(i,l,m)] = random.random()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('alignprobs_init_random.pickle', 'rb') as f:\n",
    "    q = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "dev_e = 'validation/dev.e'\n",
    "# test_e = 'testing/test/test.e'\n",
    "dev_f = 'validation/dev.f'\n",
    "# test_f = 'testing/test/test.f'\n",
    "\n",
    "with open(dev_e) as e:\n",
    "    val_sentences_e = [null + l.split() for l in e.readlines()]\n",
    "with open(dev_f) as f:\n",
    "    val_sentences_f = [l.split() for l in f.readlines()]\n",
    "\n",
    "num_val_sentences = len(val_sentences_e)\n",
    "print(num_val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is iteration  0\n",
      "-3762.0295622\n",
      "this is iteration  1\n",
      "-2597.18404836\n",
      "this is iteration  2\n",
      "-2280.22435105\n",
      "this is iteration  3\n",
      "-2199.8179577\n",
      "this is iteration  4\n",
      "-2185.46984305\n",
      "this is iteration  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:85: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2184.31489906\n",
      "this is iteration  6\n",
      "-2187.63843729\n",
      "this is iteration  7\n",
      "-2211.07547756\n",
      "this is iteration  8\n",
      "-2220.18853587\n",
      "this is iteration  9\n",
      "-2243.88200424\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAEWCAYAAADYRbjGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bdca3518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IBM model 2 with jump function EM training\n",
    "\n",
    "likelihood_list = [] #here we will store the likelihoods per iteration\n",
    "\n",
    "#We initialize q uniformly\n",
    "max_jump = 100\n",
    "jump_dist = 1. / (2 * max_jump) * np.ones([1, 2 * max_jump])\n",
    "\n",
    "#We initialize t as the results of training IBM1\n",
    "with open('transprobs_init.pickle', 'rb') as f:\n",
    "    t = dill.load(f)\n",
    "    \n",
    "num_iterations = 10\n",
    "\n",
    "for v in range(num_iterations):\n",
    "    print('this is iteration ',v)\n",
    "    counts_ef = defaultdict(lambda: defaultdict(int))\n",
    "    counts_e = defaultdict(int)\n",
    "    counts_jump = defaultdict(int)\n",
    "    \n",
    "    for k in range(100):\n",
    "        sent_f = sentences_f[k]\n",
    "        m = len(sent_f)\n",
    "        \n",
    "        sent_e = sentences_e[k]\n",
    "        l = len(sent_e)\n",
    "        \n",
    "        ##E-step\n",
    "        #Compute normalizer\n",
    "        for i in range(m):\n",
    "            Z = 0\n",
    "            for j in range(l):\n",
    "                word_z = t[sent_f[i].lower()][sent_e[j].lower()] * jump_dist[0, int(jump_func(j, i, l, m))]\n",
    "                Z += word_z\n",
    "                \n",
    "            #Increment the counts with delta\n",
    "            \n",
    "            for j in range(l):\n",
    "                \n",
    "                delta = (t[sent_f[i].lower()][sent_e[j].lower()] * jump_dist[0, int(jump_func(j, i, l, m))]) / Z\n",
    "\n",
    "                counts_ef[sent_f[i].lower()][sent_e[j].lower()] += delta\n",
    "                \n",
    "                counts_e[sent_e[j].lower()] += delta\n",
    "\n",
    "                counts_jump[int(jump_func(j,i,l,m))] += delta\n",
    "        \n",
    "        ##M-step\n",
    "        \n",
    "        for i in range(m):\n",
    "            \n",
    "            div_q = 0\n",
    "            \n",
    "            for j in range(l):\n",
    "                \n",
    "                t[sent_f[i].lower()][sent_e[j].lower()] = counts_ef[sent_f[i].lower()][sent_e[j].lower()] / counts_e[sent_e[j].lower()]\n",
    "                \n",
    "                div_q += counts_jump[int(jump_func(j,i,l,m))]\n",
    "            \n",
    "            for j in range(l):\n",
    "                \n",
    "                jump_dist[0, int(jump_func(j, i, l, m))] = counts_jump[int(jump_func(j,i,l,m))] / div_q \n",
    "                \n",
    "        \n",
    "    #Compute the log likelihood\n",
    "    likelihood = 0\n",
    "    \n",
    "    for k in range(100):\n",
    "        sent_f = sentences_f[k]\n",
    "        m = len(sent_f)\n",
    "        \n",
    "        sent_e = sentences_e[k]\n",
    "        l = len(sent_e)\n",
    "        \n",
    "        sent_likelihood = 0 \n",
    "\n",
    "        for i in range(m):\n",
    "\n",
    "            word_likelihood = -9999\n",
    "\n",
    "            best_j = -1 #to be set after the loop below\n",
    "\n",
    "            for j in range(l):\n",
    "\n",
    "                temp_likelihood = np.log(t[sent_f[i].lower()][sent_e[j].lower()]) + np.log(jump_dist[0, int(jump_func(j, i, l, m))])\n",
    "                \n",
    "                if word_likelihood == -9999 or temp_likelihood > word_likelihood:\n",
    "\n",
    "                    word_likelihood = temp_likelihood\n",
    "                    best_j = j #we can use this part for decoding later\n",
    "                    \n",
    "            sent_likelihood += word_likelihood\n",
    "    \n",
    "        likelihood += sent_likelihood\n",
    "\n",
    "    print(likelihood)\n",
    "\n",
    "    likelihood_list.append(likelihood)\n",
    "    \n",
    "    #Here we write out the NAACL files on the validation set \n",
    "#     filename = \"val_naacl_IBM2_uniform_iter\" + str(v) +\".txt\"\n",
    "#     write_val_results(filename)\n",
    "    \n",
    "    \n",
    "#Here we plot the log likelihoods per iteration    \n",
    "iteration= list(range(len(likelihood_list)))\n",
    "\n",
    "plt.plot(iteration, likelihood_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel('log likelihood')\n",
    "plt.title('Evolution of training log likelihood as a function of the iteration')\n",
    "# plt.savefig(\"EM_IBM2_initIBM1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is iteration  0\n",
      "this is iteration  1\n",
      "this is iteration  2\n",
      "this is iteration  3\n",
      "this is iteration  4\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5756e6521de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts_ef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcounts_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts_jilm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcounts_ilm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# IBM model 2 with EM training (without jump function) -- NOT WORKING DUE TO SPARSITY (deltas become 0)\n",
    "\n",
    "#We initialize q as random values and t as the results of training IBM1\n",
    "with open('alignprobs_init_random.pickle', 'rb') as f:\n",
    "    q = dill.load(f)\n",
    "\n",
    "with open('transprobs_9.pickle', 'rb') as f:\n",
    "    t = dill.load(f)\n",
    "    \n",
    "num_iterations = 10\n",
    "\n",
    "for k in range(num_iterations):\n",
    "    print('this is iteration ',k)\n",
    "    counts_ef = defaultdict(lambda: defaultdict(int))\n",
    "    counts_e = defaultdict(int)\n",
    "    counts_jilm = defaultdict(lambda: defaultdict(int))\n",
    "    counts_ilm = defaultdict(int)\n",
    "    \n",
    "    for k in range(1000):\n",
    "        sent_f = sentences_f[k]\n",
    "        m = len(sent_f)\n",
    "        \n",
    "        sent_e = sentences_e[k]\n",
    "        l = len(sent_e)\n",
    "        \n",
    "        ##E-step\n",
    "        #Compute normalizer\n",
    "        for i in range(m):\n",
    "            Z = 0\n",
    "            for j in range(l):\n",
    "                word_z = t[sent_e[j].lower()][sent_f[i].lower()] * q[j][(i,l,m)]\n",
    "                Z += word_z\n",
    "                \n",
    "            #Increment the counts with delta\n",
    "            \n",
    "            for j in range(l):\n",
    "                \n",
    "                delta = (t[sent_f[i].lower()][sent_e[j].lower()] * q[j][(i,l,m)]) / Z\n",
    "#                 if delta == 0:\n",
    "#                     delta = 0.00000000000000000000001\n",
    "                \n",
    "                counts_ef[sent_f[i].lower()][sent_e[j].lower()] += delta\n",
    "                \n",
    "                counts_e[sent_e[j].lower()] += delta\n",
    "                \n",
    "                counts_jilm[j][(i,l,m)] += delta\n",
    "                \n",
    "                counts_ilm[(i,l,m)] += delta\n",
    "        \n",
    "        ##M-step\n",
    "        for i in range(m):\n",
    "            for j in range(l):\n",
    "                \n",
    "                t[sent_f[i].lower()][sent_e[j].lower()] = counts_ef[sent_f[i].lower()][sent_e[j].lower()] / counts_e[sent_e[j].lower()]\n",
    "                \n",
    "                q[j][(i,l,m)] = counts_jilm[j][(i,l,m)] / counts_ilm[(i,l,m)]\n",
    "                \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run this after training to save the translation and alignment probabilities!!!!! \n",
    "\n",
    "filename = 'IBM2_uniform_transprobs_' + str(k) + '.pickle'                   \n",
    "with open(filename, 'wb') as f:\n",
    "    dill.dump(t,f)\n",
    "\n",
    "filename = 'IBM2_uniform_alignprobs_' + str(k) + '.pickle'                   \n",
    "with open(filename, 'wb') as f:\n",
    "    dill.dump(jump_dist,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decoding with IBM model 2\n",
    "#we try to find the most probable alignment given the translation \n",
    "#probabilities that were trained with the EM steps\n",
    "#for each word in a sentence, find highest combination of t and q \n",
    "\n",
    "def write_val_results(filename):\n",
    "    naaclfile = open(filename,\"w\") \n",
    "    for sent in range(num_val_sentences):\n",
    "        sent_e = val_sentences_e[sent]\n",
    "        sent_f = val_sentences_f[sent]\n",
    "\n",
    "        l = len(sent_e) #includes null\n",
    "        m = len(sent_f)\n",
    "\n",
    "        for i in range(m):\n",
    "            best_prob = 0\n",
    "            best_j = 0\n",
    "            for j in range(l):\n",
    "                if (t[sent_f[i].lower()][sent_e[j].lower()] * jump_dist[0, int(jump_func(j, i, l, m))]) > best_prob:\n",
    "                    best_prob = t[sent_f[i].lower()][sent_e[j].lower()] * jump_dist[0, int(jump_func(j, i, l, m))]\n",
    "                    best_j = j\n",
    "            if best_j != 0:\n",
    "                naaclfile.write(str(sent+1) + \" \" + str(best_j) + \" \" + str(i+1) + \" S\" + \"\\n\")\n",
    "    naaclfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'IBM2_uniform_alignprobs_231647.pickle'\n",
    "with open(filename, 'rb') as f:\n",
    "    t = dill.load(f)\n",
    "    \n",
    "filename = 'IBM2_uniform_transprobs_231647.pickle'\n",
    "with open(filename, 'rb') as f:\n",
    "    jump_dist = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447\n"
     ]
    }
   ],
   "source": [
    "test_e = 'testing/test/test.e'\n",
    "test_f = 'testing/test/test.f'\n",
    "\n",
    "with open(test_e) as e:\n",
    "    test_sentences_e = [null + l.split() for l in e.readlines()]\n",
    "with open(test_f) as f:\n",
    "    test_sentences_f = [l.split() for l in f.readlines()]\n",
    "\n",
    "num_test_sentences = len(test_sentences_e)\n",
    "print(num_test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decoding with IBM model 2\n",
    "#we try to find the most probable alignment given the translation \n",
    "#probabilities that were trained with the EM steps\n",
    "#for each word in a sentence, find highest combination of t and q \n",
    "\n",
    "def write_test_results(filename):\n",
    "    naaclfile = open(filename,\"w\") \n",
    "    for sent in range(num_test_sentences):\n",
    "        sent_e = test_sentences_e[sent]\n",
    "        sent_f = test_sentences_f[sent]\n",
    "\n",
    "        l = len(sent_e) #includes null\n",
    "        m = len(sent_f)\n",
    "\n",
    "        for i in range(m):\n",
    "            best_prob = 0\n",
    "            best_j = 0\n",
    "            for j in range(l):\n",
    "                if (t[sent_f[i].lower()][sent_e[j].lower()] * jump_dist[0, int(jump_func(j, i, l, m))]) > best_prob:\n",
    "                    best_prob = t[sent_f[i].lower()][sent_e[j].lower()] * jump_dist[0, int(jump_func(j, i, l, m))]\n",
    "                    best_j = j\n",
    "            if best_j != 0:\n",
    "                naaclfile.write(str(sent+1) + \" \" + str(best_j) + \" \" + str(i+1) + \" S\" + \"\\n\")\n",
    "    naaclfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_test_results('naacl_IBM2_uniform_iter9')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
